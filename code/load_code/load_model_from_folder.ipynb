{"cells":[{"cell_type":"code","execution_count":1,"id":"d7465da7-052b-40aa-9111-ae82733177e1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting import-ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: IPython in /opt/conda/miniconda3/lib/python3.8/site-packages (from import-ipynb) (8.12.2)\n","Requirement already satisfied: nbformat in /opt/conda/miniconda3/lib/python3.8/site-packages (from import-ipynb) (5.9.2)\n","Requirement already satisfied: backcall in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (0.2.0)\n","Requirement already satisfied: decorator in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (0.17.2)\n","Requirement already satisfied: matplotlib-inline in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (0.1.6)\n","Requirement already satisfied: pickleshare in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (3.0.40)\n","Requirement already satisfied: pygments>=2.4.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (2.16.1)\n","Requirement already satisfied: stack-data in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (0.6.2)\n","Requirement already satisfied: traitlets>=5 in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (5.9.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (4.8.0)\n","Requirement already satisfied: pexpect>4.3 in /opt/conda/miniconda3/lib/python3.8/site-packages (from IPython->import-ipynb) (4.8.0)\n","Requirement already satisfied: fastjsonschema in /opt/conda/miniconda3/lib/python3.8/site-packages (from nbformat->import-ipynb) (2.18.1)\n","Requirement already satisfied: jsonschema>=2.6 in /opt/conda/miniconda3/lib/python3.8/site-packages (from nbformat->import-ipynb) (4.19.2)\n","Requirement already satisfied: jupyter-core in /opt/conda/miniconda3/lib/python3.8/site-packages (from nbformat->import-ipynb) (4.10.0)\n","Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from jedi>=0.16->IPython->import-ipynb) (0.7.0)\n","Requirement already satisfied: attrs>=22.2.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (23.1.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (6.1.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/miniconda3/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2023.7.1)\n","Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/miniconda3/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (1.3.10)\n","Requirement already satisfied: referencing>=0.28.4 in /opt/conda/miniconda3/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.12.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/miniconda3/lib/python3.8/site-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n","Requirement already satisfied: wcwidth in /opt/conda/miniconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->import-ipynb) (0.2.9)\n","Requirement already satisfied: executing>=1.2.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from stack-data->IPython->import-ipynb) (2.0.1)\n","Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from stack-data->IPython->import-ipynb) (2.4.1)\n","Requirement already satisfied: pure-eval in /opt/conda/miniconda3/lib/python3.8/site-packages (from stack-data->IPython->import-ipynb) (0.2.2)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from asttokens>=2.1.0->stack-data->IPython->import-ipynb) (1.16.0)\n","Requirement already satisfied: zipp>=3.1.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.17.0)\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.4\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Ensure the accessibility between each varaiables\n","\n","!pip install import-ipynb"]},{"cell_type":"code","execution_count":2,"id":"af737ba0-418d-4479-8dcf-afd0ad5f1e95","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import StringType, DateType, FloatType, IntegerType, TimestampType, ArrayType, StructType, StructField\n","from pyspark.sql.functions import from_unixtime, sum, rank,lag, explode, expr,spark_partition_id, to_date, coalesce, lit, to_timestamp, col, month, concat, count, max, when, dayofweek, datediff,dense_rank, desc, date_format\n","import pyspark.sql.functions as F\n","from pyspark.sql.window import Window\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import re\n","from pyspark.ml.feature import Tokenizer, StopWordsRemover, Word2Vec,HashingTF,IDF, CountVectorizer,VectorAssembler\n","from pyspark.sql.functions import udf\n","from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF\n","from pyspark.ml import Pipeline,PipelineModel\n","from sparknlp.base import DocumentAssembler, Finisher\n","from sparknlp.annotator import LemmatizerModel\n","from pyspark.ml.classification import LinearSVC, LogisticRegression, LinearSVCModel\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator,BinaryClassificationEvaluator\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from google.cloud import storage\n","import sparknlp\n","import os\n","import warnings\n","import import_ipynb\n"]},{"cell_type":"code","execution_count":3,"id":"4ba112e8-9f80-4f67-981a-1c912c5b3487","metadata":{},"outputs":[],"source":["def train_test_val_split(df, train_prob = 0.7, test_prob=0.2, val_prob= 0.1):\n","    train_df, test_df, validation_df = df.randomSplit([train_prob, test_prob, val_prob],2023)\n","    return train_df, test_df, validation_df"]},{"cell_type":"code","execution_count":4,"id":"2034c541-3341-4abb-a888-0ebce2ccd8c1","metadata":{},"outputs":[],"source":["spark = SparkSession.builder.appName(\"LoadModel\").getOrCreate()\n","\n","# Get the context of the Pyspark environment\n","spark.sparkContext.getConf().getAll()\n","\n","# Store spark context as a variable\n","sc = spark.sparkContext\n","\n","stoarge_client = storage.Client()"]},{"cell_type":"code","execution_count":5,"id":"c524876b-06c1-4378-9c84-363d601b9b35","metadata":{},"outputs":[],"source":["spark = SparkSession.builder.appName(\"AddLabelColumn\").getOrCreate()\n","\n","# Get the context of the Pyspark environment\n","spark.sparkContext.getConf().getAll()\n","\n","# Store spark context as a variable\n","sc = spark.sparkContext\n","\n","stoarge_client = storage.Client()"]},{"cell_type":"code","execution_count":6,"id":"75e6775f-e2a6-464a-877c-b3374747311d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["reddit_data_df = spark.read.parquet(\"gs://msca-bdp-student-gcs/Group2_Final_Project/reddit_data/\",header=True, inferSchema=True)\n","reddit_data_df = reddit_data_df.dropna()\n","\n","train_df, test_df, validation_df = train_test_val_split(reddit_data_df)"]},{"cell_type":"code","execution_count":7,"id":"798b20cf-1de8-4ba1-be1b-fbdd57e5a5b3","metadata":{},"outputs":[],"source":["def list_all_files(bucket_name, folder_name):\n","    bucket = stoarge_client.bucket(bucket_name)\n","    file_lst = [(blob.name.split(\"/\")[2].split(\"_\")[0]) for blob in bucket.list_blobs(prefix = folder_name)]\n","    file_lst = list(set(file_lst))\n","    try:\n","        file_lst.remove(\"\")\n","    except:\n","        return file_lst\n","  \n","    return file_lst\n","\n"]},{"cell_type":"code","execution_count":8,"id":"e14ca79f-f0e0-42c2-a500-2b08261ecd91","metadata":{},"outputs":[],"source":["def test_preprocess_pipeline(train_df):\n","    tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"token\")\n","\n","    # remove stop words\n","    remover = StopWordsRemover(inputCol=\"token\", outputCol=\"filtered_token\")\n","\n","    # vecotorize the words\n","    vectorizer = CountVectorizer(inputCol=\"filtered_token\", outputCol=\"features\")\n","    idf = IDF(inputCol=\"features\", outputCol=\"tfidf_features\")\n","\n","    # assemble all features into 1 column\n","    assembler = VectorAssembler(inputCols=[\"features\",\"tfidf_features\"], outputCol=\"final_features\")\n","\n","    # Create the preprocessing piplines for the tweets\n","    pipeline = Pipeline().setStages([\n","        tokenizer,\n","        remover,\n","        vectorizer,\n","        idf,\n","        assembler\n","    ])\n","    \n","    model = pipeline.fit(train_df)\n","    return model"]},{"cell_type":"code","execution_count":9,"id":"06297f95-5555-4b4d-9bc7-3aed54c1db94","metadata":{},"outputs":[],"source":["def load_model_from_path(bucket_name,folder_name):\n","    \n","   \n","    model_lst_path = list_all_files(bucket_name, folder_name)\n","    model_lst = {}\n","    \n","    for model_name in model_lst_path:\n","        prefix = 'gs://'\n","        suffix = '_model'\n","        model_path = os.path.join(prefix, bucket_name, folder_name, model_name+suffix)\n","        print(\"Attempting to load model from path:\", model_path)\n","        try:\n","            loaded_model = PipelineModel.load(model_path)\n","            print(\"Model loaded successfully.\")\n","        except:\n","            print(\"Model loading failed\")\n","            continue\n","        model_lst[\"r/\"+ model_name] = loaded_model\n","    \n","    return model_lst"]},{"cell_type":"code","execution_count":10,"id":"7fa01b82-3fb8-4b3a-849c-be58b67a9cec","metadata":{},"outputs":[],"source":["# Tokenize and stop word removal\n","def clean_text(text):\n","    # Deal with component words\n","    re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', text)\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Remove Http / Https links in the text\n","    text = re.sub(r'http\\S+', '', text)\n","    text = re.sub(r'https\\S+', '', text)\n","    # Remove special characters and numbers\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","    # Handling repeated characters (more than 2)\n","    text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n","    # Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text"]},{"cell_type":"code","execution_count":11,"id":"695e2fa1-afa0-4e5e-9d55-3bba9b62c936","metadata":{},"outputs":[],"source":["def encode_by_tags(df,tags_lst,labelcol):\n","    \n","    df_res = df\n","    \n","    for tag in tags_lst:\n","        print(tag)\n","        df_res= df_res.withColumn(tag, when(col(labelcol) == tag, 1).otherwise(0))\n","\n","    return df_res"]},{"cell_type":"code","execution_count":12,"id":"d1ff9d75-26f3-4ceb-bfb9-0b04c4c1e51e","metadata":{},"outputs":[],"source":["def clean_df(df, inputcol):\n","    clean_text_udf = udf(clean_text, StringType())\n","    df_cleaned = df.withColumn(inputcol, clean_text_udf(df[inputcol]))\n","    return df_cleaned"]},{"cell_type":"code","execution_count":13,"id":"490c2d75-1723-46fb-aaa1-9d07d23deb96","metadata":{},"outputs":[],"source":["def get_model_spec_from_loading(test_df,model_lst,inputcol,labelcol):\n","    \n","    model_spec = {}\n","    tags_lst = [tag for tag in model_lst.keys()]\n","    print(tags_lst)\n","    \n","    # encode df by tag_lst\n","    encoded_df = encode_by_tags(test_df,tags_lst,labelcol)\n","    \n","   # clean the df \n","    df_cleaned = clean_df(encoded_df,inputcol)\n","\n","    # preprocessed the test_df\n","    preprocess_model = test_preprocess_pipeline()\n","    preprocess_df= preprocess_model.transform(df_cleaned)\n","        \n","    # test through each model\n","    for tag, model in model_lst.items():\n","        f1_evaluator = MulticlassClassificationEvaluator(labelCol=tag, predictionCol=\"prediction\", metricName=\"f1\")\n","        accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=tag, predictionCol=\"prediction\", metricName=\"accuracy\")\n","        \n","        # generate the predictions based on preprocess_df\n","        predictions = model.transform(preprocess_df)\n","        \n","        #evaluate the predictions\n","        f1_score = f1_evaluator.evaluate(predictions)\n","        accuracy = accuracy_evaluator.evaluate(predictions)\n","        \n","        model_spec[tag] = {\"f1_score\": f1_score, \"accuracy\": accuracy}\n","    return model_spec       "]},{"cell_type":"code","execution_count":null,"id":"d894b0bf-373c-45d1-9fd6-b36dda97bfce","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Fitness_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/technology_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/LifeProTips_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/books_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Foodforthought_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/sports_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/femalefashionadvice_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/lifehacks_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/relationship_model\n","Model loading failed\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/space_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/socialskills_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/history_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/EatCheapAndHealthy_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/UpliftingNews_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/gardening_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/changemyview_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/IWantToLearn_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Documentaries_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/mildlyinteresting_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/buildapc_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/AskHistorians_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/todayilearned_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Fantasy_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/explainlikeimfive_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/programming_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/malefashionadvice_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/suggestmeabook_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/gadgets_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/IAmA_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/DIY_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/gaming_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/WritingPrompts_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/bodyweightfitness_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/personalfinance_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/GetMotivated_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Damnthatsinteresting_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/philosophy_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/travel_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/askscience_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/YouShouldKnow_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/podcasts_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/tifu_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/science_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/scifi_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Showerthoughts_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/boardgames_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/SkincareAddiction_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/bestof_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/ifyoulikeblank_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Games_model\n","Model loaded successfully.\n","['r/Fitness', 'r/technology', 'r/LifeProTips', 'r/books', 'r/Foodforthought', 'r/sports', 'r/femalefashionadvice', 'r/lifehacks', 'r/space', 'r/socialskills', 'r/history', 'r/EatCheapAndHealthy', 'r/UpliftingNews', 'r/gardening', 'r/changemyview', 'r/IWantToLearn', 'r/Documentaries', 'r/mildlyinteresting', 'r/buildapc', 'r/AskHistorians', 'r/todayilearned', 'r/Fantasy', 'r/explainlikeimfive', 'r/programming', 'r/malefashionadvice', 'r/suggestmeabook', 'r/gadgets', 'r/IAmA', 'r/DIY', 'r/gaming', 'r/WritingPrompts', 'r/bodyweightfitness', 'r/personalfinance', 'r/GetMotivated', 'r/Damnthatsinteresting', 'r/philosophy', 'r/travel', 'r/askscience', 'r/YouShouldKnow', 'r/podcasts', 'r/tifu', 'r/science', 'r/scifi', 'r/Showerthoughts', 'r/boardgames', 'r/SkincareAddiction', 'r/bestof', 'r/ifyoulikeblank', 'r/Games']\n","r/Fitness\n","r/technology\n","r/LifeProTips\n","r/books\n","r/Foodforthought\n","r/sports\n","r/femalefashionadvice\n","r/lifehacks\n","r/space\n","r/socialskills\n","r/history\n","r/EatCheapAndHealthy\n","r/UpliftingNews\n","r/gardening\n","r/changemyview\n","r/IWantToLearn\n","r/Documentaries\n","r/mildlyinteresting\n","r/buildapc\n","r/AskHistorians\n","r/todayilearned\n","r/Fantasy\n","r/explainlikeimfive\n","r/programming\n","r/malefashionadvice\n","r/suggestmeabook\n","r/gadgets\n","r/IAmA\n","r/DIY\n","r/gaming\n","r/WritingPrompts\n","r/bodyweightfitness\n","r/personalfinance\n","r/GetMotivated\n","r/Damnthatsinteresting\n","r/philosophy\n","r/travel\n","r/askscience\n","r/YouShouldKnow\n","r/podcasts\n","r/tifu\n","r/science\n","r/scifi\n","r/Showerthoughts\n","r/boardgames\n","r/SkincareAddiction\n","r/bestof\n","r/ifyoulikeblank\n","r/Games\n"]},{"name":"stderr","output_type":"stream","text":["23/11/28 02:18:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n","23/11/28 02:21:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n","23/11/28 02:21:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:23:52 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:25:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:27:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:28:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:30:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:31:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:32:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:34:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:35:33 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:36:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:37:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:38:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:39:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:40:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:41:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:42:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:43:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:44:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:45:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:45:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:46:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:47:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:48:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:49:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:50:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:50:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:51:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:52:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:53:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:53:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:54:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:55:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:56:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:56:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:57:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:58:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:58:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 02:59:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:00:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:00:44 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:01:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:02:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:03:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:03:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:04:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:05:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:05:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:06:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:07:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:07:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:08:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:09:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:09:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:10:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:10:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:11:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:12:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:12:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:13:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:14:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:14:28 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 39 for reason Container marked as failed: container_1701137322263_0001_01_000039 on host: hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n","23/11/28 03:14:28 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 40 for reason Container marked as failed: container_1701137322263_0001_01_000040 on host: hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n","23/11/28 03:14:28 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 39 on hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal: Container marked as failed: container_1701137322263_0001_01_000039 on host: hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n","23/11/28 03:14:28 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 40 on hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal: Container marked as failed: container_1701137322263_0001_01_000040 on host: hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n","23/11/28 03:17:01 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 834.0 in stage 424.0 (TID 121567) (hub-msca-bdp-dphub-students-test-qinglin-sw-w5d4.c.msca-bdp-student-ap.internal executor 36): FetchFailed(BlockManagerId(39, hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal, 7337, None), shuffleId=63, mapIndex=166, mapId=119939, reduceId=834, message=\n","org.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal:7337\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:775)\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n","\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n","\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n","\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n","\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n","\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n","\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n","\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:155)\n","\tat org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)\n","\tat org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:112)\n","\tat org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)\n","\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n","\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n","\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal:7337\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n","\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n","\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n","\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\t... 1 more\n","Caused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal\n","\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n","\tat java.net.InetAddress.getAllByName0(InetAddress.java:1291)\n","\tat java.net.InetAddress.getAllByName(InetAddress.java:1144)\n","\tat java.net.InetAddress.getAllByName(InetAddress.java:1065)\n","\tat java.net.InetAddress.getByName(InetAddress.java:1015)\n","\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n","\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n","\tat java.security.AccessController.doPrivileged(Native Method)\n","\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n","\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n","\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n","\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n","\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n","\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n","\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n","\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n","\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n","\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n","\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n","\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n","\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n","\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n","\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n","\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n","\t... 2 more\n","\n",")\n","23/11/28 03:17:02 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 513.0 in stage 424.0 (TID 121247) (hub-msca-bdp-dphub-students-test-qinglin-sw-5d83.c.msca-bdp-student-ap.internal executor 31): FetchFailed(BlockManagerId(39, hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal, 7337, None), shuffleId=63, mapIndex=166, mapId=119939, reduceId=513, message=\n","org.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal:7337\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:775)\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n","\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n","\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n","\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n","\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n","\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n","\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n","\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:155)\n","\tat org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)\n","\tat org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:112)\n","\tat org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)\n","\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n","\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n","\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal:7337\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n","\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n","\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n","\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\t... 1 more\n","Caused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal\n","\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n","\tat java.net.InetAddress.getAllByName0(InetAddress.java:1291)\n","\tat java.net.InetAddress.getAllByName(InetAddress.java:1144)\n","\tat java.net.InetAddress.getAllByName(InetAddress.java:1065)\n","\tat java.net.InetAddress.getByName(InetAddress.java:1015)\n","\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n","\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n","\tat java.security.AccessController.doPrivileged(Native Method)\n","\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n","\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n","\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n","\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n","\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n","\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n","\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n","\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n","\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n","\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n","\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n","\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n","\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n","\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n","\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n","\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n","\t... 2 more\n","\n",")\n","23/11/28 03:17:03 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:17:26 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 424.1 (TID 121694) (hub-msca-bdp-dphub-students-test-qinglin-sw-w5d4.c.msca-bdp-student-ap.internal executor 36): FetchFailed(BlockManagerId(40, hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal, 7337, None), shuffleId=63, mapIndex=144, mapId=119917, reduceId=513, message=\n","org.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal:7337\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:775)\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n","\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n","\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n","\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n","\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n","\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n","\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n","\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:155)\n","\tat org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)\n","\tat org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:112)\n","\tat org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)\n","\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n","\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n","\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal:7337\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n","\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n","\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n","\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\t... 1 more\n","Caused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal\n","\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n","\tat java.net.InetAddress.getAllByName0(InetAddress.java:1291)\n","\tat java.net.InetAddress.getAllByName(InetAddress.java:1144)\n","\tat java.net.InetAddress.getAllByName(InetAddress.java:1065)\n","\tat java.net.InetAddress.getByName(InetAddress.java:1015)\n","\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n","\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n","\tat java.security.AccessController.doPrivileged(Native Method)\n","\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n","\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n","\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n","\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n","\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n","\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n","\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n","\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n","\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n","\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n","\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n","\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n","\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n","\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n","\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n","\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n","\t... 2 more\n","\n",")\n","23/11/28 03:17:26 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 424.1 (TID 121695) (hub-msca-bdp-dphub-students-test-qinglin-sw-5d83.c.msca-bdp-student-ap.internal executor 31): FetchFailed(BlockManagerId(40, hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal, 7337, None), shuffleId=63, mapIndex=144, mapId=119917, reduceId=834, message=\n","org.apache.spark.shuffle.FetchFailedException: Failed to connect to hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal:7337\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:775)\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:690)\n","\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70)\n","\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n","\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n","\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n","\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n","\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n","\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n","\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:155)\n","\tat org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)\n","\tat org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:112)\n","\tat org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)\n","\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n","\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n","\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat java.lang.Thread.run(Thread.java:750)\n","Caused by: java.io.IOException: Failed to connect to hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal:7337\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)\n","\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n","\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:105)\n","\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:153)\n","\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:181)\n","\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n","\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n","\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n","\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n","\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n","\t... 1 more\n","Caused by: java.net.UnknownHostException: hub-msca-bdp-dphub-students-test-qinglin-sw-brv9.c.msca-bdp-student-ap.internal\n","\tat java.net.InetAddress$CachedAddresses.get(InetAddress.java:764)\n","\tat java.net.InetAddress.getAllByName0(InetAddress.java:1291)\n","\tat java.net.InetAddress.getAllByName(InetAddress.java:1144)\n","\tat java.net.InetAddress.getAllByName(InetAddress.java:1065)\n","\tat java.net.InetAddress.getByName(InetAddress.java:1015)\n","\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)\n","\tat io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)\n","\tat java.security.AccessController.doPrivileged(Native Method)\n","\tat io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)\n","\tat io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)\n","\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)\n","\tat io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)\n","\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)\n","\tat io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)\n","\tat io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)\n","\tat io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)\n","\tat io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)\n","\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)\n","\tat io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n","\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n","\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n","\tat io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:604)\n","\tat io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)\n","\tat io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:984)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417)\n","\tat io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474)\n","\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n","\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n","\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n","\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n","\t... 2 more\n","\n",")\n","23/11/28 03:17:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:17:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:18:50 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:19:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:20:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:21:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:21:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:22:32 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:23:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:23:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:24:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:25:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:25:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:26:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:27:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:27:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:28:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:29:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:29:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:30:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:31:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:31:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:32:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:32:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:33:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:34:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:34:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:35:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:36:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:36:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:37:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:37:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:38:33 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:39:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:39:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:40:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:41:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","[Stage 495:====================================================>(947 + 1) / 948]\r"]},{"name":"stdout","output_type":"stream","text":["{'r/Fitness': {'f1_score': 0.9793339331253917, 'accuracy': 0.9761830673744356}, 'r/technology': {'f1_score': 0.920323135964179, 'accuracy': 0.9418568259850725}, 'r/LifeProTips': {'f1_score': 0.9576000708924204, 'accuracy': 0.9699858479294928}, 'r/books': {'f1_score': 0.9680394004424682, 'accuracy': 0.9771737017510534}, 'r/Foodforthought': {'f1_score': 0.9991634348672491, 'accuracy': 0.9994189446840196}, 'r/sports': {'f1_score': 0.9878921098055788, 'accuracy': 0.9913362255520949}, 'r/femalefashionadvice': {'f1_score': 0.9944861047442708, 'accuracy': 0.9960730459282889}, 'r/lifehacks': {'f1_score': 0.9935000792175512, 'accuracy': 0.9956273554887554}, 'r/space': {'f1_score': 0.9786004824018987, 'accuracy': 0.9838969119386014}, 'r/socialskills': {'f1_score': 0.9912008039537795, 'accuracy': 0.9940303772720472}, 'r/history': {'f1_score': 0.9977390357815209, 'accuracy': 0.9983235133964241}, 'r/EatCheapAndHealthy': {'f1_score': 0.9923084164495303, 'accuracy': 0.9948153774077289}, 'r/UpliftingNews': {'f1_score': 0.9863316564508875, 'accuracy': 0.9904656456719826}, 'r/gardening': {'f1_score': 0.979303012330125, 'accuracy': 0.9850945532109088}, 'r/changemyview': {'f1_score': 0.9621093325539654, 'accuracy': 0.9739003425195965}, 'r/IWantToLearn': {'f1_score': 0.9986430900288951, 'accuracy': 0.9990365019519678}, 'r/Documentaries': {'f1_score': 0.9931314918980155, 'accuracy': 0.9952011989822505}, 'r/mildlyinteresting': {'f1_score': 0.9074997504357233, 'accuracy': 0.9350919610052014}, 'r/buildapc': {'f1_score': 0.9486949100779153, 'accuracy': 0.9604284224427363}, 'r/AskHistorians': {'f1_score': 0.9962008306143408, 'accuracy': 0.9970711771116366}, 'r/todayilearned': {'f1_score': 0.9203696264614224, 'accuracy': 0.9458213696792602}, 'r/Fantasy': {'f1_score': 0.980600826065357, 'accuracy': 0.9846490211546159}, 'r/explainlikeimfive': {'f1_score': 0.9672924725786328, 'accuracy': 0.9763245036084454}, 'r/programming': {'f1_score': 0.9902034874031773, 'accuracy': 0.9927232931803661}, 'r/malefashionadvice': {'f1_score': 0.9930999366560124, 'accuracy': 0.9948480043553279}, 'r/suggestmeabook': {'f1_score': 0.9785005637935806, 'accuracy': 0.9837932765047226}, 'r/gadgets': {'f1_score': 0.9864700317091486, 'accuracy': 0.9908928580667594}, 'r/IAmA': {'f1_score': 0.9940800257520692, 'accuracy': 0.9957114041951919}, 'r/DIY': {'f1_score': 0.9904733733889585, 'accuracy': 0.9917426897423305}, 'r/gaming': {'f1_score': 0.816726583443252, 'accuracy': 0.8585609150919061}, 'r/WritingPrompts': {'f1_score': 0.9925471995782457, 'accuracy': 0.9942976753880575}, 'r/bodyweightfitness': {'f1_score': 0.9963420461876684, 'accuracy': 0.9972937055649219}, 'r/personalfinance': {'f1_score': 0.9543605036946722, 'accuracy': 0.9672932272475347}, 'r/GetMotivated': {'f1_score': 0.9940751191076578, 'accuracy': 0.995976273768177}, 'r/Damnthatsinteresting': {'f1_score': 0.847164446495893, 'accuracy': 0.8935233291650384}, 'r/philosophy': {'f1_score': 0.9966386886808345, 'accuracy': 0.9977030206534914}, 'r/travel': {'f1_score': 0.9861214146424747, 'accuracy': 0.9897089433419857}, 'r/askscience': {'f1_score': 0.9960543219066709, 'accuracy': 0.9973111277214068}, 'r/YouShouldKnow': {'f1_score': 0.9905917337761835, 'accuracy': 0.9933264165612274}, 'r/podcasts': {'f1_score': 0.9975594656297468, 'accuracy': 0.9982512906386318}, 'r/tifu': {'f1_score': 0.9618612747206615, 'accuracy': 0.97329684957784}, 'r/science': {'f1_score': 0.9670720457287995, 'accuracy': 0.9769287884664057}, 'r/scifi': {'f1_score': 0.9944923904933559, 'accuracy': 0.9962366030215932}, 'r/Showerthoughts': {'f1_score': 0.9283220512210837, 'accuracy': 0.9458711548112764}, 'r/boardgames': {'f1_score': 0.982360436963962, 'accuracy': 0.986331684704582}, 'r/SkincareAddiction': {'f1_score': 0.9838021606448129, 'accuracy': 0.9858599138247346}, 'r/bestof': {'f1_score': 0.9950756863069424, 'accuracy': 0.9966691476521427}, 'r/ifyoulikeblank': {'f1_score': 0.9956069379957946, 'accuracy': 0.9967631745027479}, 'r/Games': {'f1_score': 0.9647628440916595, 'accuracy': 0.9745029379563219}}\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# test_data= [(\"If you look at the example in the article, they are wildly diverging after the first sentence, leading me to belive that the prompt has been write an admit note for a person with he history of left breast cancer. I would really not like an AI to fabricate information about what tests have been conducted and what their results were. Doctors have enough on their mind as it is. They don't need to also be tasked with babysitting text generators.\",\"r/science\")]\n","# test_df = spark.createDataFrame(test_data,[\"body\",\"subreddit_name_prefixed\"])\n","\n","inputcol = \"body\"\n","labelcol = \"subreddit_name_prefixed\"\n","\n","bucket_name = 'msca-bdp-student-gcs'\n","folder_name = 'Group2_Final_Project/modelr/'\n","model_lst = load_model_from_path(bucket_name,folder_name)\n","\n","model_spec = get_model_spec_from_loading(test_df, model_lst, inputcol = \"body\",labelcol = \"subreddit_name_prefixed\")\n","print(model_spec)"]},{"cell_type":"code","execution_count":null,"id":"62a6a7b1-5870-4b21-8a60-9b65b205389d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Fitness_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/technology_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/LifeProTips_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/books_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Foodforthought_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/sports_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/femalefashionadvice_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/lifehacks_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/relationship_model\n","Model loading failed\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/space_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/socialskills_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/history_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/EatCheapAndHealthy_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/UpliftingNews_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/gardening_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/changemyview_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/IWantToLearn_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Documentaries_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/mildlyinteresting_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/buildapc_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/AskHistorians_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/todayilearned_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Fantasy_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/explainlikeimfive_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/programming_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/malefashionadvice_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/suggestmeabook_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/gadgets_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/IAmA_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/DIY_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/gaming_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/WritingPrompts_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/bodyweightfitness_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/personalfinance_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/GetMotivated_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Damnthatsinteresting_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/philosophy_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/travel_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/askscience_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/YouShouldKnow_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/podcasts_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/tifu_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/science_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/scifi_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Showerthoughts_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/boardgames_model\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/SkincareAddiction_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/bestof_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/ifyoulikeblank_model\n","Model loaded successfully.\n","Attempting to load model from path: gs://msca-bdp-student-gcs/Group2_Final_Project/modelr/Games_model\n","Model loaded successfully.\n","['r/Fitness', 'r/technology', 'r/LifeProTips', 'r/books', 'r/Foodforthought', 'r/sports', 'r/femalefashionadvice', 'r/lifehacks', 'r/space', 'r/socialskills', 'r/history', 'r/EatCheapAndHealthy', 'r/UpliftingNews', 'r/gardening', 'r/changemyview', 'r/IWantToLearn', 'r/Documentaries', 'r/mildlyinteresting', 'r/buildapc', 'r/AskHistorians', 'r/todayilearned', 'r/Fantasy', 'r/explainlikeimfive', 'r/programming', 'r/malefashionadvice', 'r/suggestmeabook', 'r/gadgets', 'r/IAmA', 'r/DIY', 'r/gaming', 'r/WritingPrompts', 'r/bodyweightfitness', 'r/personalfinance', 'r/GetMotivated', 'r/Damnthatsinteresting', 'r/philosophy', 'r/travel', 'r/askscience', 'r/YouShouldKnow', 'r/podcasts', 'r/tifu', 'r/science', 'r/scifi', 'r/Showerthoughts', 'r/boardgames', 'r/SkincareAddiction', 'r/bestof', 'r/ifyoulikeblank', 'r/Games']\n","r/Fitness\n","r/technology\n","r/LifeProTips\n","r/books\n","r/Foodforthought\n","r/sports\n","r/femalefashionadvice\n","r/lifehacks\n","r/space\n","r/socialskills\n","r/history\n","r/EatCheapAndHealthy\n","r/UpliftingNews\n","r/gardening\n","r/changemyview\n","r/IWantToLearn\n","r/Documentaries\n","r/mildlyinteresting\n","r/buildapc\n","r/AskHistorians\n","r/todayilearned\n","r/Fantasy\n","r/explainlikeimfive\n","r/programming\n","r/malefashionadvice\n","r/suggestmeabook\n","r/gadgets\n","r/IAmA\n","r/DIY\n","r/gaming\n","r/WritingPrompts\n","r/bodyweightfitness\n","r/personalfinance\n","r/GetMotivated\n","r/Damnthatsinteresting\n","r/philosophy\n","r/travel\n","r/askscience\n","r/YouShouldKnow\n","r/podcasts\n","r/tifu\n","r/science\n","r/scifi\n","r/Showerthoughts\n","r/boardgames\n","r/SkincareAddiction\n","r/bestof\n","r/ifyoulikeblank\n","r/Games\n"]},{"name":"stderr","output_type":"stream","text":["23/11/28 03:44:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n","23/11/28 03:45:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n","23/11/28 03:45:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:45:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:46:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:47:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:47:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:48:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:49:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:49:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:50:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:51:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:51:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:52:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:53:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:53:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:54:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:55:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:55:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:56:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:57:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:57:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:58:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:59:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 03:59:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:00:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:01:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:01:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:02:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:03:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:03:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:04:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:05:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:05:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:06:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:07:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:07:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:08:33 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:09:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:09:52 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:10:32 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:11:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:11:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:12:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:13:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:13:50 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:14:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:15:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:15:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:16:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:17:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:17:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:18:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:19:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:19:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:20:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:21:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:21:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:22:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:23:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:23:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:24:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:25:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:25:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:26:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:27:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:27:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:28:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:29:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:29:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:30:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:31:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:31:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:32:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:33:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:33:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:34:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:35:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:35:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:36:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:37:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:37:44 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:38:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:39:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:39:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:40:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:41:03 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:41:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:42:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:43:03 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:43:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:44:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:45:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:45:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:46:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:47:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:47:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:48:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:49:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","23/11/28 04:49:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 41.7 MiB\n","                                                                                \r"]}],"source":["# test on Youtube data \n","\n","youtube_comments_df = spark.read\\\n","            .option(\"quote\", \"\\\"\") \\\n","            .option(\"escape\", \"\\\"\") \\\n","            .option(\"multiLine\", True) \\\n","            .option(\"ignoreLeadingWhiteSpace\", True) \\\n","            .csv('gs://msca-bdp-student-gcs/Group2_Final_Project/scrapy_data_youtube/merged/youtube_comment_selected.csv', header=True, inferSchema=True)\n","\n","youtube_comments_df = youtube_comments_df.dropna()\n","\n","\n","inputcol = \"body\"\n","labelcol = \"subreddit_name_prefixed\"\n","\n","\n","bucket_name = 'msca-bdp-student-gcs'\n","folder_name = 'Group2_Final_Project/modelr/'\n","model_lst = load_model_from_path(bucket_name,folder_name)\n","\n","yotube_model_spec = get_model_spec_from_loading(youtube_comments_df, model_lst, inputcol = \"body\",labelcol = \"subreddit_name_prefixed\")\n"]},{"cell_type":"code","execution_count":null,"id":"250298f1-8deb-47fa-be0d-44c55563d833","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+----------+-------------+\n","|               model|  f1_score|test_accuracy|\n","+--------------------+----------+-------------+\n","|           r/Fitness|0.97933394|   0.97618306|\n","|        r/technology|0.92032313|    0.9418568|\n","|       r/LifeProTips|0.95760006|   0.96998584|\n","|             r/books| 0.9680394|    0.9771737|\n","|    r/Foodforthought|0.99916345|     0.999419|\n","|            r/sports| 0.9878921|    0.9913362|\n","|r/femalefashionad...| 0.9944861|   0.99607307|\n","|         r/lifehacks|0.99350005|   0.99562734|\n","|             r/space| 0.9786005|    0.9838969|\n","|      r/socialskills| 0.9912008|   0.99403036|\n","|           r/history|  0.997739|    0.9983235|\n","|r/EatCheapAndHealthy|0.99230844|   0.99481535|\n","|     r/UpliftingNews|0.98633164|   0.99046564|\n","|         r/gardening|  0.979303|   0.98509455|\n","|      r/changemyview| 0.9621093|    0.9739003|\n","|      r/IWantToLearn| 0.9986431|    0.9990365|\n","|     r/Documentaries| 0.9931315|    0.9952012|\n","| r/mildlyinteresting|0.90749973|     0.935092|\n","|          r/buildapc| 0.9486949|    0.9604284|\n","|     r/AskHistorians|0.99620086|    0.9970712|\n","|     r/todayilearned| 0.9203696|   0.94582134|\n","|           r/Fantasy|0.98060083|     0.984649|\n","| r/explainlikeimfive| 0.9672925|    0.9763245|\n","|       r/programming| 0.9902035|    0.9927233|\n","| r/malefashionadvice| 0.9930999|     0.994848|\n","|    r/suggestmeabook|0.97850055|   0.98379326|\n","|           r/gadgets|0.98647004|    0.9908929|\n","|              r/IAmA|   0.99408|    0.9957114|\n","|               r/DIY| 0.9904734|    0.9917427|\n","|            r/gaming|0.81672657|    0.8585609|\n","|    r/WritingPrompts| 0.9925472|    0.9942977|\n","| r/bodyweightfitness|0.99634206|    0.9972937|\n","|   r/personalfinance| 0.9543605|    0.9672932|\n","|      r/GetMotivated| 0.9940751|   0.99597627|\n","|r/Damnthatsintere...|0.84716445|   0.89352334|\n","|        r/philosophy| 0.9966387|     0.997703|\n","|            r/travel| 0.9861214|   0.98970896|\n","|        r/askscience|0.99605435|    0.9973111|\n","|     r/YouShouldKnow| 0.9905917|    0.9933264|\n","|          r/podcasts| 0.9975595|    0.9982513|\n","|              r/tifu|0.96186125|    0.9732968|\n","|           r/science|0.96707207|    0.9769288|\n","|             r/scifi| 0.9944924|    0.9962366|\n","|    r/Showerthoughts| 0.9283221|    0.9458712|\n","|        r/boardgames| 0.9823604|    0.9863317|\n","| r/SkincareAddiction|0.98380214|   0.98585993|\n","|            r/bestof| 0.9950757|    0.9966692|\n","|    r/ifyoulikeblank|0.99560696|   0.99676317|\n","|             r/Games|0.96476287|    0.9745029|\n","+--------------------+----------+-------------+\n","\n"]}],"source":["# convert the model into dataframe for better visualization\n","model_data = [(tag, specs[\"f1_score\"], specs[\"accuracy\"]) for tag, specs in model_spec.items()]\n","\n","\n","schema = StructType([\n","    StructField(\"model\", StringType(), True),\n","    StructField(\"f1_score\", FloatType(), True),\n","    StructField(\"test_accuracy\", FloatType(), True)\n","])\n","\n","# Create DataFrame\n","model_df = spark.createDataFrame(model_data, schema)\n","model_df.show(100)\n","\n","# save to GCS\n","model_pd = model_df.toPandas()\n","model_pd.to_csv(\"gs://msca-bdp-student-gcs/Group2_Final_Project/model_metric/model_metric.csv\")\n"]},{"cell_type":"code","execution_count":19,"id":"8842b240-6ef1-47b1-ad42-4e84f5130dd6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+----------+-------------+\n","|               model|  f1_score|test_accuracy|\n","+--------------------+----------+-------------+\n","|           r/Fitness| 0.9996584|   0.99931705|\n","|        r/technology|0.99841624|    0.9968375|\n","|       r/LifeProTips| 0.7607092|   0.83309275|\n","|             r/books| 0.9994133|    0.9988273|\n","|    r/Foodforthought| 0.9999987|   0.99999744|\n","|            r/sports| 0.9994839|   0.99896836|\n","|r/femalefashionad...|   0.99985|       0.9997|\n","|         r/lifehacks|0.99999017|   0.99998033|\n","|             r/space|0.99920106|    0.9984034|\n","|      r/socialskills| 0.9999372|   0.99987435|\n","|           r/history|0.99992603|    0.9998521|\n","|r/EatCheapAndHealthy| 0.9998769|   0.99975383|\n","|     r/UpliftingNews|0.99984956|    0.9996991|\n","|         r/gardening| 0.9991895|    0.9983803|\n","|      r/changemyview|0.99956346|    0.9991273|\n","|      r/IWantToLearn|  0.999997|   0.99999404|\n","|     r/Documentaries| 0.9999393|   0.99987864|\n","| r/mildlyinteresting| 0.3783133|   0.53815913|\n","|          r/buildapc|0.99554807|   0.99113554|\n","|     r/AskHistorians| 0.9997666|    0.9995333|\n","|     r/todayilearned|0.99900794|   0.99801785|\n","|           r/Fantasy|0.99803156|    0.9960708|\n","| r/explainlikeimfive| 0.9991056|   0.99821275|\n","|       r/programming|0.99928063|   0.99856234|\n","| r/malefashionadvice| 0.9996871|   0.99937433|\n","|    r/suggestmeabook|0.99791527|    0.9958392|\n","|           r/gadgets| 0.9999551|   0.99991024|\n","|              r/IAmA| 0.9998722|    0.9997444|\n","|               r/DIY|0.99896383|    0.9979298|\n","|            r/gaming| 0.9884204|     0.977106|\n","|    r/WritingPrompts| 0.9993949|   0.99879056|\n","| r/bodyweightfitness| 0.9998568|   0.99971366|\n","|   r/personalfinance|0.90991294|   0.93767023|\n","|      r/GetMotivated| 0.9999564|    0.9999128|\n","|r/Damnthatsintere...|0.99826103|    0.9965281|\n","|        r/philosophy| 0.9999543|   0.99990857|\n","|            r/travel| 0.9987561|   0.99751526|\n","|        r/askscience| 0.9999825|   0.99996495|\n","|     r/YouShouldKnow|0.99985427|   0.99970853|\n","|          r/podcasts| 0.9999658|   0.99993163|\n","|              r/tifu|0.99939364|     0.998788|\n","|           r/science|0.99963146|    0.9992632|\n","|             r/scifi| 0.9998102|    0.9996205|\n","|    r/Showerthoughts| 0.9975993|   0.99521005|\n","|        r/boardgames| 0.9981804|    0.9963674|\n","| r/SkincareAddiction| 0.9976173|     0.995246|\n","|            r/bestof| 0.9999876|    0.9999752|\n","|    r/ifyoulikeblank| 0.9996302|   0.99926066|\n","|             r/Games|0.99898356|   0.99796915|\n","+--------------------+----------+-------------+\n","\n"]}],"source":["youtube_model_data = [(tag, specs[\"f1_score\"], specs[\"accuracy\"]) for tag, specs in yotube_model_spec.items()]\n","\n","youtube_model_df = spark.createDataFrame(youtube_model_data, schema)\n","youtube_model_df.show(100)\n","\n","schema = StructType([\n","    StructField(\"model\", StringType(), True),\n","    StructField(\"f1_score\", FloatType(), True),\n","    StructField(\"test_accuracy\", FloatType(), True)\n","])\n","\n","youtube_model_pd = youtube_model_df.toPandas()\n","youtube_model_pd.to_csv(\"gs://msca-bdp-student-gcs/Group2_Final_Project/model_metric/youtube_model_metric.csv\")"]},{"cell_type":"code","execution_count":null,"id":"896aac53-b254-47b0-a87a-a9fc41262788","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":5}
