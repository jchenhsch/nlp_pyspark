{"cells": [{"cell_type": "code", "execution_count": 5, "id": "a7109118-36e9-475c-abe0-ef1bd9ca1313", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.types import StringType, DateType, FloatType, IntegerType, TimestampType, ArrayType, StructType, StructField\nfrom pyspark.sql.functions import from_unixtime, sum, rank,lag, explode, expr,spark_partition_id, to_date, coalesce, lit, to_timestamp, col, month, concat, count, max, when, dayofweek, datediff,dense_rank, desc, date_format\nimport pyspark.sql.functions as F\nfrom pyspark.sql.window import Window\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, Word2Vec,HashingTF,IDF, CountVectorizer,VectorAssembler\nfrom pyspark.sql.functions import udf\nfrom pyspark.ml.feature import Tokenizer, CountVectorizer, IDF\nfrom pyspark.ml import Pipeline,PipelineModel\nfrom sparknlp.base import DocumentAssembler, Finisher\nfrom sparknlp.annotator import LemmatizerModel\nfrom pyspark.ml.classification import LinearSVC, LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator,BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nimport sparknlp\nimport warnings\nfrom google.cloud import storage\nimport os\n"}, {"cell_type": "code", "execution_count": 6, "id": "22862787-9682-4e7f-baf2-300324ad12f3", "metadata": {}, "outputs": [], "source": "spark = SparkSession.builder.appName(\"AddLabelColumn\").getOrCreate()\n\n# Get the context of the Pyspark environment\nspark.sparkContext.getConf().getAll()\n\n# Store spark context as a variable\nsc = spark.sparkContext\n\nstoarge_client = storage.Client()\n"}, {"cell_type": "code", "execution_count": 7, "id": "862f0fa1-2a9c-4d33-9315-0582cc8eb2f4", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['gs://msca-bdp-student-gcs/Group2_Final_Project/scrapy_data_youtube/comments_Books.csv', 'gs://msca-bdp-student-gcs/Group2_Final_Project/scrapy_data_youtube/comments_Financial Advice.csv', 'gs://msca-bdp-student-gcs/Group2_Final_Project/scrapy_data_youtube/comments_Relationship.csv', 'gs://msca-bdp-student-gcs/Group2_Final_Project/scrapy_data_youtube/comments_interesting.csv', 'gs://msca-bdp-student-gcs/Group2_Final_Project/scrapy_data_youtube/comments_life tips.csv']\n"}], "source": "def list_csv_files(bucket_name, folder_name):\n    bucket = stoarge_client.bucket(bucket_name)\n    # list folder with csv suffix and make sure the subdirectory file is not listed (so merged file will not be concated in the merged_df)\n    return [(\"gs://\"+ bucket_name + \"/\" +blob.name) for blob in bucket.list_blobs(prefix=folder_name) if blob.name.endswith('.csv') and not '/' in blob.name[len(folder_name):]]\n\nproject_name = \"msca-bdp-student-ap\"\nbucket_name = 'msca-bdp-student-gcs'\nfolder_name = 'Group2_Final_Project/scrapy_data_youtube/'\n\ndir_file_lst = list_csv_files(bucket_name, folder_name)\nprint(dir_file_lst)"}, {"cell_type": "code", "execution_count": 8, "id": "811a7492-b17c-4008-aa51-376ead83a527", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-----+\n|  tag|\n+-----+\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n|Books|\n+-----+\nonly showing top 20 rows\n\n"}], "source": "def merge_youtube_df(dir_file_lst, labelCol, saved_path):\n    res_df = None\n\n    for file_path in dir_file_lst:\n        splitted_path = file_path.split(\"/\")\n        file_name = splitted_path[-1].split(\".\")[0]\n        file_name = file_name.split(\"_\")[1]\n\n        curr_df = spark.read \\\n                    .option(\"quote\", \"\\\"\") \\\n                    .option(\"escape\", \"\\\"\") \\\n                    .option(\"multiLine\", True) \\\n                    .option(\"ignoreLeadingWhiteSpace\", True) \\\n                    .csv(file_path, header=True, inferSchema=True)\n        curr_df = curr_df.withColumn(labelCol, lit(file_name))\n\n        if res_df is None:\n            res_df = curr_df\n        else:\n            res_df = res_df.union(curr_df)\n    \n    res_pd = res_df.toPandas()\n    res_pd.to_csv(saved_path,index=False)\n            \n#    res_df.write.mode(\"overwrite\").options(delimiter=\";\", quote='\"', escape='\"').csv(saved_path, header=True)\n     \n   \n    return res_df\n\n# Usage\nlabelCol = \"tag\"\nsaved_path = \"gs://msca-bdp-student-gcs/Group2_Final_Project/scrapy_data_youtube/merged/youtube_comment.csv\"\nmerged_df = merge_youtube_df(dir_file_lst, labelCol,saved_path)\nmerged_df.select(col(labelCol)).show()\n"}, {"cell_type": "code", "execution_count": 9, "id": "0cecf919-7c6b-4811-a7ec-065eed56c3da", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- Video Title: string (nullable = true)\n |-- Video URL: string (nullable = true)\n |-- Views: string (nullable = true)\n |-- Publication Date: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Likes: string (nullable = true)\n |-- Channel URL: string (nullable = true)\n |-- Channel Name: string (nullable = true)\n |-- Channel Image: string (nullable = true)\n |-- Channel Subscribers: string (nullable = true)\n |-- Comments: string (nullable = true)\n |-- tag: string (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+----------------+---------+\n|             tag|tag_count|\n+----------------+---------+\n|    Relationship|   240780|\n|Financial Advice|    70880|\n|           Books|   132824|\n|     interesting|   548336|\n|       life tips|   196188|\n+----------------+---------+\n\n"}], "source": "youtube_comments = spark.read \\\n            .option(\"quote\", \"\\\"\") \\\n            .option(\"escape\", \"\\\"\") \\\n            .option(\"multiLine\", True) \\\n            .option(\"ignoreLeadingWhiteSpace\", True) \\\n            .csv('gs://msca-bdp-student-gcs/Group2_Final_Project/scrapy_data_youtube/merged/youtube_comment.csv', header=True, inferSchema=True)\n\nyoutube_comments.printSchema()\nyoutube_comments_grouped = youtube_comments.select(col(\"Comments\"),col(\"Likes\"),col(\"tag\")).groupBy(col(\"tag\")).agg(count(\"*\").alias(\"tag_count\"))\nyoutube_comments_grouped.show()\n\nyoutube_comments_modified = youtube_comments.withColumn(\n    \"subreddit_name_prefixed\",\n    when(col(\"tag\") == \"problem-solving\", \"r/YouShouldKnow\")\n    .when(col(\"tag\") == \"Relationship\", \"r/relationship_advice\")\n    .when(col(\"tag\") == \"Programming\", \"r/programming\")\n    .when(col(\"tag\") == \"Financial Advice\", \"r/personalfinance\")\n    .when(col(\"tag\") == \"Books\", \"r/Books\")\n    .when(col(\"tag\") == \"interesting\", \"r/mildlyinteresting\")\n    .when(col(\"tag\") == \"life tips\", \"r/LifeProTips\")\n    .otherwise(lit(None))  # Set to null if none of the conditions are met\n) \\\n    .withColumn(\"body\", col(\"Comments\"))"}, {"cell_type": "code", "execution_count": 10, "id": "5570d465-93a0-4633-abb3-67ad1af64a38", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "youtube_comments_selected = youtube_comments_modified.select(col(\"body\"),col(\"Likes\"),col(\"subreddit_name_prefixed\"))\nres_saved_path = \"gs://msca-bdp-student-gcs/Group2_Final_Project/scrapy_data_youtube/merged/youtube_comment_selected.csv\"\n\nyoutube_comments_selected.toPandas().to_csv(res_saved_path,index=False)"}, {"cell_type": "code", "execution_count": 11, "id": "b4343ae7-4098-4b6e-a97c-61f1d95d2161", "metadata": {}, "outputs": [], "source": "def list_all_files(bucket_name, folder_name):\n    bucket = stoarge_client.bucket(bucket_name)\n    file_lst = [('r/'+ blob.name.split(\"/\")[2].split(\"_\")[0]) for blob in bucket.list_blobs(prefix = folder_name)]\n    file_lst = list(set(file_lst))\n  \n    return file_lst"}, {"cell_type": "code", "execution_count": 12, "id": "30fb3841-710e-4991-9bf0-840464c26b3d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['r/askscience', 'r/ifyoulikeblank', 'r/mildlyinteresting', 'r/programming', 'r/lifehacks', 'r/Showerthoughts', 'r/Damnthatsinteresting', 'r/SkincareAddiction', 'r/Documentaries', 'r/malefashionadvice', 'r/IWantToLearn', 'r/Foodforthought', 'r/bestof', 'r/socialskills', 'r/travel', 'r/YouShouldKnow', 'r/changemyview', 'r/suggestmeabook', 'r/tifu', 'r/Games', 'r/AskHistorians', 'r/DIY', 'r/scifi', 'r/gadgets', 'r/EatCheapAndHealthy', 'r/IAmA', 'r/space', 'r/personalfinance', 'r/relationship', 'r/science', 'r/', 'r/UpliftingNews', 'r/books', 'r/philosophy', 'r/Fantasy', 'r/Fitness', 'r/sports', 'r/GetMotivated', 'r/WritingPrompts', 'r/explainlikeimfive', 'r/femalefashionadvice', 'r/gaming', 'r/bodyweightfitness', 'r/podcasts', 'r/LifeProTips', 'r/technology', 'r/buildapc', 'r/history', 'r/gardening', 'r/todayilearned', 'r/boardgames']\n"}], "source": "bucket_name = 'msca-bdp-student-gcs'\nfolder_name = 'Group2_Final_Project/modelr/'\ntrained_tags = list_all_files(bucket_name, folder_name)\n\n\nprint(trained_tags)"}, {"cell_type": "code", "execution_count": 44, "id": "098986ce-2144-4705-a4fc-01dc0de45f45", "metadata": {}, "outputs": [], "source": "# DO NOT DELETE - Pandas approach download and re-upload\n# storage_client = storage.Client()\n\n# Process each CSV file and merge them.\n# def process_and_merge_csv_files(bucket_name, folder_name):\n    \n    \n#     csv_files = list_csv_files(bucket_name, folder_name)\n#     df_lst = []\n\n#     for file_name in csv_files:\n#         # Download the file\n#         blob = storage_client.bucket(bucket_name).blob(file_name)\n#         blob.download_to_filename(os.path.basename(file_name))\n\n#         # Process the file\n#         df = pd.read_csv(os.path.basename(file_name))\n#         label = os.path.basename(file_name).split('_')[1] if file_name.lower().startswith('comments') else os.path.basename(file_name)\n#         df['tag'] = label\n\n#         df_lst.append(df)\n\n#         # Clean up local file\n#         os.remove(os.path.basename(file_name))\n\n#     # Merge all dataframes\n#     merged_df = pd.concat(df_lst, ignore_index=True)\n#     return merged_df\n\n# # Replace with your bucket name and folder name\n# bucket_name = 'msca-bdp-student-gcs'\n# folder_name = 'Group2_Final_Project/scrapy_data_youtube/'\n\n# # Process and merge CSV files\n# merged_df = process_and_merge_csv_files(bucket_name, folder_name)\n# merged_df.to_csv('youtube_comments.csv', index=False)\n\n# Save the merged DataFrame as a new CSV file\n\n# blob = storage_client.bucket(bucket_name).blob(folder_name + 'merged/' + 'youtube_comments.csv')\n# blob.upload_from_filename('youtube_comments.csv')\n"}, {"cell_type": "code", "execution_count": null, "id": "32356272-c992-4ef0-bd29-1bd9081be504", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}